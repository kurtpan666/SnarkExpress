\documentclass[11pt]{article}

\usepackage[colorlinks=true, linkcolor=magenta, citecolor=magenta, urlcolor=magenta, backref=page]{hyperref}
\renewcommand*{\backrefalt}[4]{
    \ifcase #1 
        No citation in the text.
    \or
        (In page #2).
    \else
        (In pages #2).
    \fi}
        
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{dutchcal}
\usepackage{mathbbol}
\usepackage[keys,
advantage,
operators ,
sets,
adversary,
landau,
probability,
notions,
logic,
ff ,
mm,
primitives,
events,
complexity,
asymptotics,
keys]{cryptocode}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[section]


\begin{document}
\title{ZKExpress (2025.08)}
\author{Kurt Pan @ \href{https://zkpunk.pro}{ZKPunk}}
\date{\today}
\maketitle
\tableofcontents

\section{\cite{cryptoeprint:2025/1388} Collaborative zkSNARKs with Sublinear Prover Time and Constant Proof Size}
We propose a new collaborative zkSNARK scheme with $O\left(\frac{C}{n} \log \frac{C}{n}\right)$ prover time and $O(1)$ proof size with $n$ servers for a circuit of size $C$. 
An adversary compromising less than $\frac{n}{4}$ servers cannot learn any information about the witness. 
The core of our technique lies in a new zkSNARK scheme for the Plonkish constraint system that is friendly to \emph{packed secret sharing}. We utilize \emph{bivariate polynomials} to avoid a large Fast Fourier Transform on the entire witness, which was the major bottleneck in prior work. We also construct permutation constraints based on logarithmic derivatives and univariate sumcheck to avoid the computation of prefix products. Finally, we build a bivariate polynomial commitment scheme that can be computed directly on packed secret shares.
Experimental results show that for a circuit of size $2^{20}$, with 128 servers, our scheme can accelerate the proof generation by $36.2 \times$ compared to running the zkSNARK on a single server. The prover time of our system is $25.9 \times$ faster than the prior work of zkSaaS. The proof size of our scheme is only 960 Bytes.

\section{\cite{cryptoeprint:2025/1390} Optimizing Backend Verification in zk-Rollup Architectures}
This paper presents a comprehensive implementation of the Tokamak zkEVM verifier, specifically optimized for the BLS12-381 elliptic curve operations introduced by EIP-2537. We detail the complete verification architecture, from EVM compatible data formatting for pairing checks, multi-scalar multiplication (MSM), and elliptic curve addition, to the non-interactive protocol design between prover and verifier.
Our key contribution lies in novel optimization techniques that substantially reduce on-chain verification costs. 
Through strategic polynomial aggregation and scalar factorization, we minimize G1 exponentiations from 40 to 31, achieving gas savings of 108,000 units per verification. 
Additionally, we introduce a dynamic barycentric interpolation method that replaces computationally intensive FFT operations,
resulting in 92-95\% gas reduction for sparse polynomial evaluations. We further present proof aggregation strategies that minimize precompile calls while maintaining the 128-bit security guarantees of BLS12-381.

\section{\cite{cryptoeprint:2025/1408} $\mathsf{qedb}$: Expressive and Modular Verifiable Databases (without {SNARKs})}
One of our primary contributions is a foundational framework that cleanly separates VDB logic from cryptographic instantiations. At its essence, it resembles other common information theoretic frameworks, such as Polynomial Interactive Oracle Proofs (PIOPs). At the same time it diverges from existing approaches by being slightly specialized for the database setting. We demonstrate how to instantiate our framework using modern pairing-based linear-map vector commitments and set accumulators. More in general, we show that our building blocks can be derived from extractable homomorphic polynomial commitments. Being  modular, our approach permits alternative instantiations, such as with lattice-based polynomial commitments enabling post-quantum security.

\section{\cite{cryptoeprint:2025/1411} BACON: An Improved Vector Commitment Construction with Applications to Signatures}
Inspired by the large-GGM based BAVC and the cGGM tree, this paper proposes BACON, a BAVC with aborts scheme by leveraging a large cGGM tree. BACON executes multiple instances of AVC in a single batch and enables an abort mechanism to probabilistically reduce the commitment size. We prove that BACON is secure under the ideal cipher model and the random oracle model. We also discuss the possible application of the proposed BACON, i.e., FAEST version 2. Furthermore, because the number of hash calls in a large cGGM tree is halved compared with that used in a large GGM tree, theoretically, our BACON is more efficient than the state-of-the-art BAVC scheme.

\section{\cite{cryptoeprint:2025/1412} AVPEU: Anonymous Verifiable Presentations with Extended Usability}

In this paper, we present Anonymous Verifiable Presentations with Extended Usability (AVPEU), a novel framework that addresses this limitation (cannot effectively verify cross-domain credentials while maintaining anonymity.) through the introduction of a notary system. At the technical core of AVPEU lies our proposed randomizable message-hiding signature scheme. We provide both a generic construction of AVPEU and specific implementations based on Boneh-Boyen-Shacham (BBS), Camenisch-Lysyanskaya (CL), and Pointcheval-Sanders (PS) signature. Our experimental results demonstrate the feasibility of these schemes.

\section{\cite{cryptoeprint:2025/1413} When Can We Incrementally Prove Computations of Arbitrary Depth?}
First, we revisit the security analysis, in the unbounded-depth regime, of the canonical construction of IVC based on the recursive composition of SNARKs. We extend this analysis to include SNARKs that are straightline extractable in the algebraic group model (AGM) and some additional oracle model. As a consequence of our result, we obtain novel instantiations of IVC for unbounded-depth computations based on AGM-based SNARKs, such as Groth16 or Marlin, to name a few—an important class of SNARKs not captured by similar analyses in prior work [Chiesa et al. TCC 2024]. Second, we consider incremental proof systems for arbitrary depth computations in which full-blown extractability is not necessary. We study under what conditions they can be instantiated from the recursive composition of "plain" building blocks (SNARKs, folding, accumulation schemes), that is without requiring special straightline extractability. We introduce incremental functional commitments (incremental FC), a primitive that allows one to commit to a large data $D$ and later prove a function $f(D)$. The key aspect is that both the committing and proving functionalities operate incrementally, processing $D$ in a streaming, piece-by-piece manner. Also, like in standard FCs, their security property is a form of evaluation binding, a notion that is weaker than knowledge-soundness (it states that it is hard to produce two valid proofs for the same commitment and two distinct outputs). Our second main result consists of a construction of incremental FCs based on recursive composition of SNARKs and its security analysis, which shows that arbitrarily deep compositions of primitives with non-straightline extractors do not suffer from inherent security limitations.

\section{\cite{cryptoeprint:2025/1414} Data Availability Sampling with Repair}
First, we provide a new definitional framework that formalizes the notion of repair, along with the security guarantees that a DAS scheme must provide. Second, we propose a new DAS scheme designed with efficient repair in mind, based on locally-correctable multiplicity codes. To facilitate using these codes, we introduce a new multivariate polynomial commitment scheme that (i) supports efficient openings of partial derivatives of a committed polynomial, (ii) supports fast batch opening proof generation at many points, and (iii) has an algorithm to recompute (repair) opening proofs at a point from only a few other proofs. The proposed scheme improves upon the state-of-the-art Ethereum Fulu DAS scheme, slated for deployment in late 2025/early 2026, in storage overhead, repair bandwidth and coordination, while only slightly increasing dispersal cost and sampling bandwidth. Our techniques readily carry over to data availability schemes based on verifiable information dispersal (VID).

\section{\cite{cryptoeprint:2025/1420} Coral: Fast Succinct Non-Interactive Zero-Knowledge CFG Proofs}
We introduce Coral, a system for proving in zero-
knowledge that a committed byte stream corresponds to a
structured object in accordance to a Context Free Grammar.
Once a prover establishes the validity of the parsed object with Coral, they can selectively prove facts about the object—such as fields in Web API responses or in JSON Web Tokens—–to third
parties or blockchains. Coral reduces the problem of correct
parsing to a few simple checks over a left-child right-sibling tree and introduces a novel segmented memory abstraction that
unifies and extends prior constructions for RAM in zkSNARKs.

\section{\cite{cryptoeprint:2025/1421} Efficient randomized strong 2-source non-malleable extractor for any linear min-entropy}
In this work, we construct a two-source non-malleable extractor in the Common Reference String (CRS) model, where a random low-degree polynomial is sampled once and made accessible to independent random sources, the distinguisher, and the tamperer.
Our results advance the state of non-malleable cryptographic primitives, with applications in secure storage, leakage-resilient cryptography, and privacy amplification. By eliminating the need for strong computational hardness assumptions, our techniques provide a more foundational and widely applicable method for randomness extraction.
We also show, that the requirements on CRS for our application are so mild that the CRS can be sampled with 
 party computation even when one of the parties is malicious (setting in which establishing unbiased coins is impossible).
\section{\cite{cryptoeprint:2025/1422} Design ZK-NR: A Post-Quantum Layered Protocol for Legally Explainable Zero-Knowledge Non-Repudiation Attestation}
This article presents the architectural design of Zero Knowledge Non-Repudiation (ZK-NR), a layered cryptographic protocol enabling post-quantum secure, legally interpretable, and verifiably non-repudiable attestations. Built upon STARK-based zero-knowledge proofs, hybrid post-quantum signatures, and entropy-accumulating ledger anchoring, ZK-NR satisfies the structural properties of both the Q2CSI framework and the NIZK-E model. The protocol achieves semantic interpretability by structurally separating contextual proofs from bounded explanations, while maintaining cryptographic soundness under the Universal Composability framework. 

\section{\cite{cryptoeprint:2025/1434} TLShare: Private Authenticated MPC and FHE Inputs Over TLS}
We introduce TLShare, a framework that extracts authenticated data from a TLS connection and imports it into secure multiparty computation (MPC) or fully homomorphic encryption (FHE), without requiring server-side changes or exposing client credentials. Unlike prior work, TLShare allows the payload itself, not just a predicate about it, to serve as private input to secure downstream computation. TLShare supports combining verifiable inputs across multiple clients and servers, enabling new applications such as privacy-preserving financial risk assessment and collaborative analytics. We design three protocols for TLShare: one for MPC using verifiable secret sharing, and two for FHE using interactive and non-interactive zero-knowledge proofs, each ensuring input authenticity, integrity, and end-to-end privacy. We evaluate all three protocols of TLShare over both LAN and WAN settings, comparing their trade-offs and demonstrating their practicality.

\section{\cite{cryptoeprint:2025/1446} zip: Reducing Proof Sizes for Hash-Based SNARGs}
We present a non-recursive proof compression technique to reduce the size of hash-based succinct arguments. The technique is black-box in the underlying succinct arguments, requires no trusted setup, can be instantiated from standard assumptions (and even when 
P=NP !) and is concretely efficient.

\section{\cite{cryptoeprint:2025/1473} Time-Space Trade-Offs for Sumcheck}
We study time-space tradeoffs for the prover of the sumcheck protocol in the streaming model, and provide upper and lower bounds that tightly characterize the efficiency achievable by the prover.

\bibliographystyle{alpha}
\bibliography{kurt}

\end{document}